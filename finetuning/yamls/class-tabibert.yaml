model_source: "hf"
hf_model_name: TabiBERT
model_path: boun-tabilab/TabiBERT
tokenizer_name: ${model_path}

max_duration: 10ep   

batch_size: 32
device_eval_microbatch_size: ${batch_size}
device_train_microbatch_size: ${batch_size}
global_train_batch_size: ${batch_size}

optimizer:
  name: decoupled_adamw
  lr: 2.0e-5
  betas:
  - 0.9
  - 0.98
  eps: 1.0e-06
  weight_decay: 1.0e-5

is_lower: False

# Best Hyperparameters for TabiBERT:
# wmt16:               5.00E-06	    1.00E-06	10	    32
# msmarco:             2.00E-05  	1.00E-05	10	    32
# scifact:             3.00E-05	    1.00E-06	 9	    16
# quora:               2.00E-05  	1.00E-06	10	    32
# apps_tr:             3.00E-05	    1.00E-06	 8	    16
# fiqa:                3.00E-05	    1.00E-06	 4	    32
# nfcorpus:            3.00E-05	    1.00E-06	 4	    16

# stack_overflow:      3.00E-05	    1.00E-05	10	    32
# cosqa_tr:            3.00E-05	    1.00E-05	10	    32
# code_search:         3.00E-05	    1.00E-05	10	    32

# news_cat:            2.00E-05	    1.00E-05	7	    16
# product_reviews:     
# bil_tweet_news:      3.00E-05  	1.00E-05	10	    32
# gender_hate_speech:  3.00E-05	    1.00E-06	10	    16
# prod_review:         2.00E-05	    1.00E-06	1	    16
# pubmed_rct:          2.00E-05	    1.00E-06	10	    32
# sci_cite_TR:         3.00E-05	    1.00E-06	10	    16
# thesis_abstract:     3.00E-05	    1.00E-05	10	    16

# wiki_ner:            3.00E-05	    1.00E-05	10	    16
# wiki_ann_ner:        3.00E-05	    1.00E-05	10	    16
# pos_ud_boun:         3.00E-05	    1.00E-06	10	    32
# pos_ud_imst:         3.00E-05	    1.00E-06    10	    16

# sick_tr:             3.00E-05	    1.00E-05	10	    16
# sts:                 3.00E-05	    1.00E-06	10	    16

# multinli:            3.00E-05	    1.00E-06	10	    32
# snli:                3.00E-05	    1.00E-06	10	    32
# med_nli:             3.00E-05	    1.00E-05	10	    16

# tquad:               3.00E-05     1.00E-06    10      32
# xquad:               3.00E-05	    1.00E-06	 7      16
